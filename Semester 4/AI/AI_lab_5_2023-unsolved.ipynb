{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 8)),\n",
    "    ('activation', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(8, 2)),\n",
    "    ('activation2', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 8)),\n",
    "    ('activation', nn.ReLU()),\n",
    "    ('output', nn.Linear(8, 2)),\n",
    "    ('activation2', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),\n",
    "    ('activation', nn.Tanh()),\n",
    "    ('output', nn.Linear(4, 2)),\n",
    "    ('activation2', nn.Tanh())\n",
    "]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (activation): Sigmoid()\n",
      "  (output): Linear(in_features=8, out_features=2, bias=True)\n",
      "  (activation2): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=2, bias=True)\n",
      "  (activation2): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (activation): Tanh()\n",
      "  (output): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (activation2): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "\n",
    "data_in = torch.tensor(data, dtype=torch.float32)\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data_out = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "]\n",
    "\n",
    "data_target = torch.tensor(data_out, dtype=torch.float32)\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.1)\n",
    "\n",
    "criterion2 = nn.MSELoss()\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.3)\n",
    "\n",
    "criterion3 = nn.MSELoss()\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Epoch [100/10000], Loss: 0.2200\n",
      "Epoch [200/10000], Loss: 0.2174\n",
      "Epoch [300/10000], Loss: 0.2167\n",
      "Epoch [400/10000], Loss: 0.2160\n",
      "Epoch [500/10000], Loss: 0.2154\n",
      "Epoch [600/10000], Loss: 0.2147\n",
      "Epoch [700/10000], Loss: 0.2140\n",
      "Epoch [800/10000], Loss: 0.2132\n",
      "Epoch [900/10000], Loss: 0.2123\n",
      "Epoch [1000/10000], Loss: 0.2114\n",
      "Epoch [1100/10000], Loss: 0.2103\n",
      "Epoch [1200/10000], Loss: 0.2092\n",
      "Epoch [1300/10000], Loss: 0.2079\n",
      "Epoch [1400/10000], Loss: 0.2065\n",
      "Epoch [1500/10000], Loss: 0.2050\n",
      "Epoch [1600/10000], Loss: 0.2034\n",
      "Epoch [1700/10000], Loss: 0.2016\n",
      "Epoch [1800/10000], Loss: 0.1997\n",
      "Epoch [1900/10000], Loss: 0.1976\n",
      "Epoch [2000/10000], Loss: 0.1954\n",
      "Epoch [2100/10000], Loss: 0.1931\n",
      "Epoch [2200/10000], Loss: 0.1907\n",
      "Epoch [2300/10000], Loss: 0.1882\n",
      "Epoch [2400/10000], Loss: 0.1857\n",
      "Epoch [2500/10000], Loss: 0.1831\n",
      "Epoch [2600/10000], Loss: 0.1805\n",
      "Epoch [2700/10000], Loss: 0.1780\n",
      "Epoch [2800/10000], Loss: 0.1755\n",
      "Epoch [2900/10000], Loss: 0.1730\n",
      "Epoch [3000/10000], Loss: 0.1706\n",
      "Epoch [3100/10000], Loss: 0.1682\n",
      "Epoch [3200/10000], Loss: 0.1660\n",
      "Epoch [3300/10000], Loss: 0.1638\n",
      "Epoch [3400/10000], Loss: 0.1617\n",
      "Epoch [3500/10000], Loss: 0.1596\n",
      "Epoch [3600/10000], Loss: 0.1577\n",
      "Epoch [3700/10000], Loss: 0.1559\n",
      "Epoch [3800/10000], Loss: 0.1541\n",
      "Epoch [3900/10000], Loss: 0.1524\n",
      "Epoch [4000/10000], Loss: 0.1508\n",
      "Epoch [4100/10000], Loss: 0.1493\n",
      "Epoch [4200/10000], Loss: 0.1478\n",
      "Epoch [4300/10000], Loss: 0.1464\n",
      "Epoch [4400/10000], Loss: 0.1451\n",
      "Epoch [4500/10000], Loss: 0.1438\n",
      "Epoch [4600/10000], Loss: 0.1426\n",
      "Epoch [4700/10000], Loss: 0.1415\n",
      "Epoch [4800/10000], Loss: 0.1404\n",
      "Epoch [4900/10000], Loss: 0.1393\n",
      "Epoch [5000/10000], Loss: 0.1383\n",
      "Epoch [5100/10000], Loss: 0.1373\n",
      "Epoch [5200/10000], Loss: 0.1363\n",
      "Epoch [5300/10000], Loss: 0.1354\n",
      "Epoch [5400/10000], Loss: 0.1344\n",
      "Epoch [5500/10000], Loss: 0.1335\n",
      "Epoch [5600/10000], Loss: 0.1325\n",
      "Epoch [5700/10000], Loss: 0.1315\n",
      "Epoch [5800/10000], Loss: 0.1306\n",
      "Epoch [5900/10000], Loss: 0.1296\n",
      "Epoch [6000/10000], Loss: 0.1285\n",
      "Epoch [6100/10000], Loss: 0.1274\n",
      "Epoch [6200/10000], Loss: 0.1263\n",
      "Epoch [6300/10000], Loss: 0.1251\n",
      "Epoch [6400/10000], Loss: 0.1239\n",
      "Epoch [6500/10000], Loss: 0.1226\n",
      "Epoch [6600/10000], Loss: 0.1212\n",
      "Epoch [6700/10000], Loss: 0.1198\n",
      "Epoch [6800/10000], Loss: 0.1183\n",
      "Epoch [6900/10000], Loss: 0.1167\n",
      "Epoch [7000/10000], Loss: 0.1151\n",
      "Epoch [7100/10000], Loss: 0.1133\n",
      "Epoch [7200/10000], Loss: 0.1115\n",
      "Epoch [7300/10000], Loss: 0.1097\n",
      "Epoch [7400/10000], Loss: 0.1077\n",
      "Epoch [7500/10000], Loss: 0.1057\n",
      "Epoch [7600/10000], Loss: 0.1036\n",
      "Epoch [7700/10000], Loss: 0.1014\n",
      "Epoch [7800/10000], Loss: 0.0992\n",
      "Epoch [7900/10000], Loss: 0.0969\n",
      "Epoch [8000/10000], Loss: 0.0946\n",
      "Epoch [8100/10000], Loss: 0.0922\n",
      "Epoch [8200/10000], Loss: 0.0898\n",
      "Epoch [8300/10000], Loss: 0.0873\n",
      "Epoch [8400/10000], Loss: 0.0848\n",
      "Epoch [8500/10000], Loss: 0.0823\n",
      "Epoch [8600/10000], Loss: 0.0798\n",
      "Epoch [8700/10000], Loss: 0.0773\n",
      "Epoch [8800/10000], Loss: 0.0747\n",
      "Epoch [8900/10000], Loss: 0.0722\n",
      "Epoch [9000/10000], Loss: 0.0697\n",
      "Epoch [9100/10000], Loss: 0.0672\n",
      "Epoch [9200/10000], Loss: 0.0648\n",
      "Epoch [9300/10000], Loss: 0.0624\n",
      "Epoch [9400/10000], Loss: 0.0601\n",
      "Epoch [9500/10000], Loss: 0.0578\n",
      "Epoch [9600/10000], Loss: 0.0555\n",
      "Epoch [9700/10000], Loss: 0.0534\n",
      "Epoch [9800/10000], Loss: 0.0512\n",
      "Epoch [9900/10000], Loss: 0.0492\n",
      "Epoch [10000/10000], Loss: 0.0472\n",
      "Model 2\n",
      "Epoch [100/10000], Loss: 0.0001\n",
      "Epoch [200/10000], Loss: 0.0000\n",
      "Epoch [300/10000], Loss: 0.0000\n",
      "Epoch [400/10000], Loss: 0.0000\n",
      "Epoch [500/10000], Loss: 0.0000\n",
      "Epoch [600/10000], Loss: 0.0000\n",
      "Epoch [700/10000], Loss: 0.0000\n",
      "Epoch [800/10000], Loss: 0.0000\n",
      "Epoch [900/10000], Loss: 0.0000\n",
      "Epoch [1000/10000], Loss: 0.0000\n",
      "Epoch [1100/10000], Loss: 0.0000\n",
      "Epoch [1200/10000], Loss: 0.0000\n",
      "Epoch [1300/10000], Loss: 0.0000\n",
      "Epoch [1400/10000], Loss: 0.0000\n",
      "Epoch [1500/10000], Loss: 0.0000\n",
      "Epoch [1600/10000], Loss: 0.0000\n",
      "Epoch [1700/10000], Loss: 0.0000\n",
      "Epoch [1800/10000], Loss: 0.0000\n",
      "Epoch [1900/10000], Loss: 0.0000\n",
      "Epoch [2000/10000], Loss: 0.0000\n",
      "Epoch [2100/10000], Loss: 0.0000\n",
      "Epoch [2200/10000], Loss: 0.0000\n",
      "Epoch [2300/10000], Loss: 0.0000\n",
      "Epoch [2400/10000], Loss: 0.0000\n",
      "Epoch [2500/10000], Loss: 0.0000\n",
      "Epoch [2600/10000], Loss: 0.0000\n",
      "Epoch [2700/10000], Loss: 0.0000\n",
      "Epoch [2800/10000], Loss: 0.0000\n",
      "Epoch [2900/10000], Loss: 0.0000\n",
      "Epoch [3000/10000], Loss: 0.0000\n",
      "Epoch [3100/10000], Loss: 0.0000\n",
      "Epoch [3200/10000], Loss: 0.0000\n",
      "Epoch [3300/10000], Loss: 0.0000\n",
      "Epoch [3400/10000], Loss: 0.0000\n",
      "Epoch [3500/10000], Loss: 0.0000\n",
      "Epoch [3600/10000], Loss: 0.0000\n",
      "Epoch [3700/10000], Loss: 0.0000\n",
      "Epoch [3800/10000], Loss: 0.0000\n",
      "Epoch [3900/10000], Loss: 0.0000\n",
      "Epoch [4000/10000], Loss: 0.0000\n",
      "Epoch [4100/10000], Loss: 0.0000\n",
      "Epoch [4200/10000], Loss: 0.0000\n",
      "Epoch [4300/10000], Loss: 0.0000\n",
      "Epoch [4400/10000], Loss: 0.0000\n",
      "Epoch [4500/10000], Loss: 0.0000\n",
      "Epoch [4600/10000], Loss: 0.0000\n",
      "Epoch [4700/10000], Loss: 0.0000\n",
      "Epoch [4800/10000], Loss: 0.0000\n",
      "Epoch [4900/10000], Loss: 0.0000\n",
      "Epoch [5000/10000], Loss: 0.0000\n",
      "Epoch [5100/10000], Loss: 0.0000\n",
      "Epoch [5200/10000], Loss: 0.0000\n",
      "Epoch [5300/10000], Loss: 0.0000\n",
      "Epoch [5400/10000], Loss: 0.0000\n",
      "Epoch [5500/10000], Loss: 0.0000\n",
      "Epoch [5600/10000], Loss: 0.0000\n",
      "Epoch [5700/10000], Loss: 0.0000\n",
      "Epoch [5800/10000], Loss: 0.0000\n",
      "Epoch [5900/10000], Loss: 0.0000\n",
      "Epoch [6000/10000], Loss: 0.0000\n",
      "Epoch [6100/10000], Loss: 0.0000\n",
      "Epoch [6200/10000], Loss: 0.0000\n",
      "Epoch [6300/10000], Loss: 0.0000\n",
      "Epoch [6400/10000], Loss: 0.0000\n",
      "Epoch [6500/10000], Loss: 0.0000\n",
      "Epoch [6600/10000], Loss: 0.0000\n",
      "Epoch [6700/10000], Loss: 0.0000\n",
      "Epoch [6800/10000], Loss: 0.0000\n",
      "Epoch [6900/10000], Loss: 0.0000\n",
      "Epoch [7000/10000], Loss: 0.0000\n",
      "Epoch [7100/10000], Loss: 0.0000\n",
      "Epoch [7200/10000], Loss: 0.0000\n",
      "Epoch [7300/10000], Loss: 0.0000\n",
      "Epoch [7400/10000], Loss: 0.0000\n",
      "Epoch [7500/10000], Loss: 0.0000\n",
      "Epoch [7600/10000], Loss: 0.0000\n",
      "Epoch [7700/10000], Loss: 0.0000\n",
      "Epoch [7800/10000], Loss: 0.0000\n",
      "Epoch [7900/10000], Loss: 0.0000\n",
      "Epoch [8000/10000], Loss: 0.0000\n",
      "Epoch [8100/10000], Loss: 0.0000\n",
      "Epoch [8200/10000], Loss: 0.0000\n",
      "Epoch [8300/10000], Loss: 0.0000\n",
      "Epoch [8400/10000], Loss: 0.0000\n",
      "Epoch [8500/10000], Loss: 0.0000\n",
      "Epoch [8600/10000], Loss: 0.0000\n",
      "Epoch [8700/10000], Loss: 0.0000\n",
      "Epoch [8800/10000], Loss: 0.0000\n",
      "Epoch [8900/10000], Loss: 0.0000\n",
      "Epoch [9000/10000], Loss: 0.0000\n",
      "Epoch [9100/10000], Loss: 0.0000\n",
      "Epoch [9200/10000], Loss: 0.0000\n",
      "Epoch [9300/10000], Loss: 0.0000\n",
      "Epoch [9400/10000], Loss: 0.0000\n",
      "Epoch [9500/10000], Loss: 0.0000\n",
      "Epoch [9600/10000], Loss: 0.0000\n",
      "Epoch [9700/10000], Loss: 0.0000\n",
      "Epoch [9800/10000], Loss: 0.0000\n",
      "Epoch [9900/10000], Loss: 0.0000\n",
      "Epoch [10000/10000], Loss: 0.0000\n",
      "Model 3\n",
      "Epoch [100/10000], Loss: 0.1376\n",
      "Epoch [200/10000], Loss: 0.0358\n",
      "Epoch [300/10000], Loss: 0.0065\n",
      "Epoch [400/10000], Loss: 0.0020\n",
      "Epoch [500/10000], Loss: 0.0010\n",
      "Epoch [600/10000], Loss: 0.0006\n",
      "Epoch [700/10000], Loss: 0.0004\n",
      "Epoch [800/10000], Loss: 0.0003\n",
      "Epoch [900/10000], Loss: 0.0002\n",
      "Epoch [1000/10000], Loss: 0.0002\n",
      "Epoch [1100/10000], Loss: 0.0002\n",
      "Epoch [1200/10000], Loss: 0.0001\n",
      "Epoch [1300/10000], Loss: 0.0001\n",
      "Epoch [1400/10000], Loss: 0.0001\n",
      "Epoch [1500/10000], Loss: 0.0001\n",
      "Epoch [1600/10000], Loss: 0.0001\n",
      "Epoch [1700/10000], Loss: 0.0001\n",
      "Epoch [1800/10000], Loss: 0.0001\n",
      "Epoch [1900/10000], Loss: 0.0000\n",
      "Epoch [2000/10000], Loss: 0.0000\n",
      "Epoch [2100/10000], Loss: 0.0000\n",
      "Epoch [2200/10000], Loss: 0.0000\n",
      "Epoch [2300/10000], Loss: 0.0000\n",
      "Epoch [2400/10000], Loss: 0.0000\n",
      "Epoch [2500/10000], Loss: 0.0000\n",
      "Epoch [2600/10000], Loss: 0.0000\n",
      "Epoch [2700/10000], Loss: 0.0000\n",
      "Epoch [2800/10000], Loss: 0.0000\n",
      "Epoch [2900/10000], Loss: 0.0000\n",
      "Epoch [3000/10000], Loss: 0.0000\n",
      "Epoch [3100/10000], Loss: 0.0000\n",
      "Epoch [3200/10000], Loss: 0.0000\n",
      "Epoch [3300/10000], Loss: 0.0000\n",
      "Epoch [3400/10000], Loss: 0.0000\n",
      "Epoch [3500/10000], Loss: 0.0000\n",
      "Epoch [3600/10000], Loss: 0.0000\n",
      "Epoch [3700/10000], Loss: 0.0000\n",
      "Epoch [3800/10000], Loss: 0.0000\n",
      "Epoch [3900/10000], Loss: 0.0000\n",
      "Epoch [4000/10000], Loss: 0.0000\n",
      "Epoch [4100/10000], Loss: 0.0000\n",
      "Epoch [4200/10000], Loss: 0.0000\n",
      "Epoch [4300/10000], Loss: 0.0000\n",
      "Epoch [4400/10000], Loss: 0.0000\n",
      "Epoch [4500/10000], Loss: 0.0000\n",
      "Epoch [4600/10000], Loss: 0.0000\n",
      "Epoch [4700/10000], Loss: 0.0000\n",
      "Epoch [4800/10000], Loss: 0.0000\n",
      "Epoch [4900/10000], Loss: 0.0000\n",
      "Epoch [5000/10000], Loss: 0.0000\n",
      "Epoch [5100/10000], Loss: 0.0000\n",
      "Epoch [5200/10000], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5300/10000], Loss: 0.0000\n",
      "Epoch [5400/10000], Loss: 0.0000\n",
      "Epoch [5500/10000], Loss: 0.0000\n",
      "Epoch [5600/10000], Loss: 0.0000\n",
      "Epoch [5700/10000], Loss: 0.0000\n",
      "Epoch [5800/10000], Loss: 0.0000\n",
      "Epoch [5900/10000], Loss: 0.0000\n",
      "Epoch [6000/10000], Loss: 0.0000\n",
      "Epoch [6100/10000], Loss: 0.0000\n",
      "Epoch [6200/10000], Loss: 0.0000\n",
      "Epoch [6300/10000], Loss: 0.0000\n",
      "Epoch [6400/10000], Loss: 0.0000\n",
      "Epoch [6500/10000], Loss: 0.0000\n",
      "Epoch [6600/10000], Loss: 0.0000\n",
      "Epoch [6700/10000], Loss: 0.0000\n",
      "Epoch [6800/10000], Loss: 0.0000\n",
      "Epoch [6900/10000], Loss: 0.0000\n",
      "Epoch [7000/10000], Loss: 0.0000\n",
      "Epoch [7100/10000], Loss: 0.0000\n",
      "Epoch [7200/10000], Loss: 0.0000\n",
      "Epoch [7300/10000], Loss: 0.0000\n",
      "Epoch [7400/10000], Loss: 0.0000\n",
      "Epoch [7500/10000], Loss: 0.0000\n",
      "Epoch [7600/10000], Loss: 0.0000\n",
      "Epoch [7700/10000], Loss: 0.0000\n",
      "Epoch [7800/10000], Loss: 0.0000\n",
      "Epoch [7900/10000], Loss: 0.0000\n",
      "Epoch [8000/10000], Loss: 0.0000\n",
      "Epoch [8100/10000], Loss: 0.0000\n",
      "Epoch [8200/10000], Loss: 0.0000\n",
      "Epoch [8300/10000], Loss: 0.0000\n",
      "Epoch [8400/10000], Loss: 0.0000\n",
      "Epoch [8500/10000], Loss: 0.0000\n",
      "Epoch [8600/10000], Loss: 0.0000\n",
      "Epoch [8700/10000], Loss: 0.0000\n",
      "Epoch [8800/10000], Loss: 0.0000\n",
      "Epoch [8900/10000], Loss: 0.0000\n",
      "Epoch [9000/10000], Loss: 0.0000\n",
      "Epoch [9100/10000], Loss: 0.0000\n",
      "Epoch [9200/10000], Loss: 0.0000\n",
      "Epoch [9300/10000], Loss: 0.0000\n",
      "Epoch [9400/10000], Loss: 0.0000\n",
      "Epoch [9500/10000], Loss: 0.0000\n",
      "Epoch [9600/10000], Loss: 0.0000\n",
      "Epoch [9700/10000], Loss: 0.0000\n",
      "Epoch [9800/10000], Loss: 0.0000\n",
      "Epoch [9900/10000], Loss: 0.0000\n",
      "Epoch [10000/10000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "print('Model 1')\n",
    "num_epochs1 = 10000\n",
    "for epoch1 in range(num_epochs1):\n",
    "    outputs1 = model1(data_in)\n",
    "    loss1 = criterion1(outputs1, data_target)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    \n",
    "    loss1.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if(epoch1+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch1+1}/{num_epochs1}], Loss: {loss1.item():.4f}')\n",
    "        \n",
    "print('Model 2')\n",
    "num_epochs2 = 10000\n",
    "for epoch2 in range(num_epochs2):\n",
    "    outputs2 = model2(data_in)\n",
    "    loss2 = criterion2(outputs2, data_target)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    \n",
    "    loss2.backward()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    if(epoch2+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch2+1}/{num_epochs2}], Loss: {loss2.item():.4f}')\n",
    "\n",
    "print('Model 3')        \n",
    "num_epochs3 = 10000\n",
    "for epoch3 in range(num_epochs3):\n",
    "    outputs3 = model3(data_in)\n",
    "    loss3 = criterion3(outputs3, data_target)\n",
    "    \n",
    "    optimizer3.zero_grad()\n",
    "    \n",
    "    loss3.backward()\n",
    "    optimizer3.step()\n",
    "    \n",
    "    if(epoch3+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch3+1}/{num_epochs3}], Loss: {loss3.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Training Accuracy: 1.0000\n",
      "Model 2\n",
      "Training Accuracy: 1.0000\n",
      "Model 3\n",
      "Training Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# visualize the resuts\n",
    "with torch.no_grad():\n",
    "    outputs = model1(data_in)\n",
    "    predicted = (outputs >=0.5).float()\n",
    "    accuracy = (predicted == data_target).float().mean()\n",
    "    print('Model 1')\n",
    "    print(f'Training Accuracy: {accuracy.item():.4f}')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    outputs2 = model2(data_in)\n",
    "    predicted2 = (outputs2 >=0.5).float()\n",
    "    accuracy2 = (predicted2 == data_target).float().mean()\n",
    "    print('Model 2')\n",
    "    print(f'Training Accuracy: {accuracy2.item():.4f}')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    outputs3 = model3(data_in)\n",
    "    predicted3 = (outputs3 >=0.5).float()\n",
    "    accuracy3 = (predicted3 == data_target).float().mean()\n",
    "    print('Model 3')\n",
    "    print(f'Training Accuracy: {accuracy3.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Weights:\n",
      "hidden.weight tensor([[-0.6071,  1.1620],\n",
      "        [-0.7484, -0.3451],\n",
      "        [-1.8478, -1.1296],\n",
      "        [ 2.4899,  2.7514],\n",
      "        [-1.5560, -0.3700],\n",
      "        [-0.0538, -0.9849],\n",
      "        [-1.8616, -2.2302],\n",
      "        [-0.6511, -1.1940]])\n",
      "hidden.bias tensor([ 1.0081,  0.2478,  1.5437, -0.8034,  0.1672, -0.2943,  2.9554, -0.1692])\n",
      "output.weight tensor([[ 0.2443, -0.6848, -3.1498,  3.6458, -1.7308, -0.7657, -4.3299, -1.1354],\n",
      "        [-1.3777, -0.1629,  0.1590,  1.7743, -0.0462, -0.1433,  1.2640, -0.6921]])\n",
      "output.bias tensor([ 0.4414, -0.8167])\n",
      "Model 2 Weights:\n",
      "hidden.weight tensor([[-1.9489, -2.4356],\n",
      "        [ 0.4361,  6.3671],\n",
      "        [-1.3716, -1.4694],\n",
      "        [-4.1460, -4.0331],\n",
      "        [-0.3620, -1.3421],\n",
      "        [-0.0942,  0.0500],\n",
      "        [-1.9755, -2.6170],\n",
      "        [-3.8289,  3.8289]])\n",
      "hidden.bias tensor([-1.1839e-01, -1.9392e+00, -2.3589e+00,  4.1478e+00, -1.9345e+00,\n",
      "        -4.3962e-01, -1.2721e+00, -4.0178e-06])\n",
      "output.weight tensor([[-1.8694,  3.8039,  1.4923, -4.1754, -1.6906,  0.0084,  1.0980, -4.8704],\n",
      "        [ 0.3409, -3.7981, -1.8837, -4.4753,  1.7065, -0.2965, -0.2921,  5.0908]])\n",
      "output.bias tensor([-8.2519,  8.2976])\n",
      "Model 3 Weights:\n",
      "hidden.weight tensor([[ 1.7504, -0.7923],\n",
      "        [-3.2213,  2.0515],\n",
      "        [ 1.3219, -2.9802],\n",
      "        [-2.0109, -2.0427]])\n",
      "hidden.bias tensor([ 0.1127, -0.6457, -0.0231, -0.0147])\n",
      "output.weight tensor([[ 0.6534, -1.6051, -2.1710, -0.7165],\n",
      "        [-0.6805,  1.5548,  2.1474, -3.0526]])\n",
      "output.bias tensor([-1.0456,  0.9637])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# print model wights\n",
    "print('Model 1 Weights:')\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "print('Model 2 Weights:')\n",
    "for name, param in model2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "print('Model 3 Weights:')\n",
    "for name, param in model3.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
